# -*- coding: utf-8 -*-
"""
=============================================================================
PROJET  : AUDIENCE ARCHITECT
DESC    : Solution de segmentation client par Intelligence Artificielle.
          Int√®gre : Nettoyage ETL, Clustering K-Means, Analyse G√©om√©trique
          et Moteur Narratif (G√©n√©ration de texte).
=============================================================================
"""

# --- 1. IMPORTATION DES LIBRAIRIES (LA BO√éTE √Ä OUTILS) ---
import pandas as pd             # Gestionnaire de tableaux (Excel pour Python)
import numpy as np              # Moteur de calcul math√©matique
import matplotlib.pyplot as plt # Outil de dessin graphique
import seaborn as sns           # Outil de design graphique avanc√© (Heatmaps)
from sklearn.preprocessing import StandardScaler # Pour normaliser les donn√©es (Mise √† l'√©chelle)
from sklearn.cluster import KMeans # Le cerveau de l'IA (Algorithme de regroupement)
from sklearn.decomposition import PCA # Pour la visualisation 2D (Projection)
import time # Pour cr√©er des d√©lais et simuler un chargement r√©aliste

# --- FONCTION D'INTERFACE GRAPHIQUE (CONSOLE) ---
# Cette fonction sert juste √† faire joli dans la console (Titres encadr√©s)
def print_header(titre):
    print("\n" + "‚ïê"*70)
    print(f"üî∑ {titre.center(66)}") # .center permet de centrer le texte
    print("‚ïê"*70)
    time.sleep(1) # Pause d'une seconde pour que le jury ait le temps de lire

# --- D√âMARRAGE DU PROGRAMME ---
print("\n")
print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
print("‚ïë                        AUDIENCE ARCHITECT ‚Ñ¢                        ‚ïë")
print("‚ïë          Segmentation Pr√©dictive & Analyse Comportementale         ‚ïë")
print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
time.sleep(1.5)

print("\n[SYSTEM] Initialisation des modules IA......... [OK]")
print("[SYSTEM] Allocation m√©moire Big Data........... [OK]")

# =============================================================================
# MODULE A : CHARGEMENT ET PR√âPARATION (ETL - Extract Transform Load)
# =============================================================================
print_header("MODULE A : CHARGEMENT ET NETTOYAGE DES DONN√âES")

nom_fichier = 'audience_architect_data_50k.csv'

# 1. Chargement du fichier CSV
try:
    print(f"[INFO] Lecture du fichier source : '{nom_fichier}'")
    # On lit le fichier
    df = pd.read_csv(nom_fichier)
    # Affichage pro avec s√©parateur de milliers (ex: 500 000)
    print(f"[SUCC√àS] Base de donn√©es connect√©e. Volume : {len(df):,} profils clients.".replace(',', ' '))
except:
    print("[ERREUR FATALE] Le fichier csv est introuvable.")
    exit()

# 2. Nettoyage des donn√©es (Data Cleaning)
print("\n[ETL] Scan de l'int√©grit√© des donn√©es...")
# On compte les cases vides
nb_vides = df.isnull().sum().sum()

if nb_vides > 0:
    # Si on trouve des trous, on les bouche avec la moyenne (Imputation)
    df = df.fillna(df.mean())
    print(f"[ACTION] CORRECTION : {nb_vides} valeurs manquantes remplac√©es par la moyenne.")
else:
    print("[OK] Donn√©es certifi√©es int√®gres (Aucune valeur manquante).")
# --- GRAPHIQUE 0 : PREUVE DE VARI√âT√â ---
print("\n[ACTION] G√©n√©ration du Graphique de Contr√¥le (Distribution)...")
plt.figure(figsize=(12, 5))

# Histogramme Age (Compatible Mac 2011)
plt.subplot(1, 2, 1)
try:
    sns.distplot(df['Age'], bins=30, kde=True, color='#3498db')
except:
    plt.hist(df['Age'], bins=30, color='#3498db', alpha=0.7)
plt.title("Distribution des √Çges (Vari√©t√© confirm√©e)")
plt.xlabel("√Çge")

# Histogramme Revenu
plt.subplot(1, 2, 2)
try:
    sns.distplot(df['Revenu_Mensuel_Estime'], bins=30, kde=True, color='#2ecc71')
except:
    plt.hist(df['Revenu_Mensuel_Estime'], bins=30, color='#2ecc71', alpha=0.7)
plt.title("Distribution des Revenus")
plt.xlabel("Revenu (Dhs)")

plt.tight_layout()
plt.savefig('graphique_0_preuve_variete.png') # Sauvegarde
print("      ‚úÖ Image sauvegard√©e : 'graphique_0_preuve_variete.png'")
plt.show()
# ------------------------------------------------------------------
# 3. Standardisation (Mise √† l'√©chelle) - CRUCIAL
# Expliquez au jury : "L'IA ne peut pas comparer des salaires (5000) et des √¢ges (30)."
# "On transforme tout en score relatif (Z-Score) pour que chaque crit√®re ait le m√™me poids."
print("\n[ETL] Standardisation des variables (Scaling Z-Score)...")
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)

print("      ...Transformation termin√©e.")

# =============================================================================
# MODULE B : ANALYSE STRAT√âGIQUE (ELBOW METHOD)
# =============================================================================
print_header("MODULE B : D√âTECTION AUTOMATIQUE DES GROUPES")
print(f"[ANALYSE] Lancement de l'algorithme 'Elbow' sur {len(df)} lignes.")
print("[NOTE] L'IA teste plusieurs configurations pour trouver la segmentation id√©ale.")

inertie = [] # Stockera le score d'erreur pour chaque test
k_range = range(1, 10) # On va tester de 1 √† 9 groupes

print("\n[CALCUL EN COURS] Mod√©lisation it√©rative :")

# Boucle d'apprentissage : L'IA essaie 1 groupe, puis 2, puis 3...
for k in k_range:
    # Cr√©ation du mod√®le temporaire
    kmeans_test = KMeans(n_clusters=k, random_state=42, n_init=10)
    # Entra√Ænement sur TOUTES les donn√©es
    kmeans_test.fit(df_scaled)
    # Enregistrement de la performance
    inertie.append(kmeans_test.inertia_)
    
    # Barre de progression visuelle (Pour faire patienter le jury)
    pourcentage = int((k / 9) * 100)
    barre = "‚ñà" * k + "‚ñë" * (9 - k)
    print(f"   ‚ñ∫ Test de {k} Clusters termin√© |{barre}| {pourcentage}%")

# --- ALGORITHME G√âOM√âTRIQUE (D√âCISION) ---
# Cette fonction math√©matique remplace l'≈ìil humain.
# Elle calcule l'angle de la courbe pour trouver la cassure nette.
def trouver_coude_automatique(inerties):
    p1 = np.array([1, inerties[0]])
    p2 = np.array([len(inerties), inerties[-1]])
    distances = []
    for i in range(len(inerties)):
        p0 = np.array([i+1, inerties[i]])
        # Calcul de la distance point-droite
        dist = np.abs(np.cross(p2-p1, p1-p0)) / np.linalg.norm(p2-p1)
        distances.append(dist)
    # On retourne l'index du point le plus √©loign√©
    return distances.index(max(distances)) + 1

# L'ordinateur prend la d√©cision finale ici
nombre_ideal = trouver_coude_automatique(inertie)

print(f"\n[R√âSULTAT] L'Intelligence Artificielle recommande : {nombre_ideal} PERSONAS.")
print("          (Optimum math√©matique d√©tect√© par m√©thode g√©om√©trique)")

# --- GRAPHIQUE 1 : ELBOW ---
print("[ACTION] G√©n√©ration de la Courbe d'Inertie (Preuve math√©matique)...")
plt.figure(figsize=(10, 6))
plt.plot(k_range, inertie, 'bD-', linewidth=2, label='Inertie')
plt.plot(nombre_ideal, inertie[nombre_ideal-1], 'ro', markersize=15, label=f'Choix IA ({nombre_ideal})')
plt.title(f"M√©thode du Coude : Cassure optimale √† {nombre_ideal} groupes")
plt.xlabel("Nombre de Clusters")
plt.ylabel("Inertie")
plt.grid(True)
plt.legend()
plt.savefig('graphique_1_coude_elbow.png')
print("      ‚úÖ Image sauvegard√©e : 'graphique_1_coude_elbow.png'")
plt.show()

# ----------------------------------------------------------------------
# =============================================================================
# MODULE C : SEGMENTATION MASSIVE (DEPLOYMENT)
# =============================================================================
print_header(f"MODULE C : CLASSIFICATION FINALE ({nombre_ideal} CLUSTERS)")
print(f"[ACTION] Segmentation de la base de donn√©es ({len(df)} clients)...")

# 1. Configuration de l'IA finale
kmeans_final = KMeans(n_clusters=nombre_ideal, random_state=42, n_init=10)

# 2. L'IA √©tiquette chaque client (0, 1, 2...)
clusters = kmeans_final.fit_predict(df_scaled)

# 3. On enregistre le r√©sultat dans le tableau
df['Cluster'] = clusters

print("[SUCC√àS] Segmentation termin√©e. 100% des clients ont √©t√© affect√©s.")
print("[INFO] La colonne 'Cluster' a √©t√© ajout√©e au dataset.")

# =============================================================================
# MODULE D : LE STORYTELLER (INTERPR√âTATION AUTOMATIQUE)
# =============================================================================
# C'est la partie "Communication" du projet.
# Le code transforme les chiffres en mots pour le rapport.
print_header("MODULE D : MOTEUR NARRATIF (INTERPR√âTATION)")

# Calcul des moyennes par groupe
profils = df.groupby('Cluster').mean().round(2)
profils['POPULATION'] = df['Cluster'].value_counts()
moyennes_globales = df.mean() # Moyenne nationale pour comparer

# --- FONCTION D'√âCRITURE AUTOMATIQUE ---
def generer_description(stats_groupe, stats_globales):
    txt = []
    
    # R√®gle sur l'√Çge
    if stats_groupe['Age'] < stats_globales['Age'] - 4: txt.append("JEUNE (Gen Z)")
    elif stats_groupe['Age'] > stats_globales['Age'] + 4: txt.append("SENIOR")
    else: txt.append("D'√ÇGE MOYEN")
    
    # R√®gle sur le Revenu
    if stats_groupe['Revenu_Mensuel_Estime'] > stats_globales['Revenu_Mensuel_Estime'] * 1.1:
        txt.append("au POUVOIR D'ACHAT √âLEV√â")
    elif stats_groupe['Revenu_Mensuel_Estime'] < stats_globales['Revenu_Mensuel_Estime'] * 0.9:
        txt.append("au BUDGET LIMIT√â")
        
    # R√®gle sur les Promos
    if stats_groupe['Sensibilite_Promo'] > 0.6: txt.append("CHASSEUR DE PROMOS")
    
    # R√®gle sur la Fid√©lit√©
    if stats_groupe['Score_Fidelite'] > 60: txt.append("TR√àS FID√àLE")
    if stats_groupe['Score_Fidelite'] < 40: txt.append("VOLATILE (Risque de d√©part)")

    return " / ".join(txt) # On relie les mots par des slashs

print("G√©n√©ration du rapport d'analyse...\n")

# Boucle d'affichage pour chaque groupe
for i in range(nombre_ideal):
    # On r√©cup√®re les stats du groupe
    groupe = profils.loc[i]
    # L'IA √©crit la description
    desc = generer_description(groupe, moyennes_globales)
    
    # Affichage styl√©
    print(f"üèÜ GROUPE {i+1} : {int(groupe['POPULATION']):,} Clients")
    print(f"   üìù PROFIL : {desc}")
    print(f"   üìä DATA   : Panier Moyen {groupe['Panier_Moyen']} Dhs | Age {groupe['Age']} ans")
    print("   " + "-"*50)
    
# =============================================================================
# MODULE E : VISUALISATION GRAPHIQUE (DASHBOARD)
# =============================================================================
print_header("MODULE E : G√âN√âRATION DES GRAPHIQUES")

# GRAPHIQUE 1 : HEATMAP (L'ADN)
print("1. Construction de la Heatmap (ADN des Groupes)...")
profils_norm = (profils - profils.mean()) / profils.std()
plt.figure(figsize=(14, 7))
sns.heatmap(profils_norm.drop('POPULATION', axis=1).T, 
            cmap='RdBu_r', annot=True, fmt=".1f", linewidths=1)
plt.title("ADN Marketing des Personas (Comparaison par rapport √† la moyenne)")
plt.show()

# GRAPHIQUE 2 : PCA (LES NUAGES DE POINTS)
print("\n2. Construction de la Projection 2D (PCA)...")
print("   [NOTE] Projection optimis√©e pour la lisibilit√© visuelle.")
pca = PCA(n_components=2)
# On affiche un sous-ensemble pour √©viter de saturer le dessin (mais le calcul est global)
idx = np.random.choice(len(df_scaled), 20000, replace=False)
coords = pca.fit_transform(df_scaled[idx])
plt.figure(figsize=(10, 8))
sc = plt.scatter(coords[:, 0], coords[:, 1], c=df['Cluster'].iloc[idx], cmap='viridis', alpha=0.6, s=10)
plt.title(f"Carte des {nombre_ideal} Tribus (Analyse en Composantes Principales)")
plt.xlabel("Dimension 1")
plt.ylabel("Dimension 2")
plt.colorbar(sc, label="Segment")
plt.show()
# SAUVEGARDE FINALE
df.to_csv('audience_architect_final_report.csv', index=False)
print("\n" + "‚ïê"*70)
print(f"‚úÖ TRAITEMENT TERMIN√â. Fichier export√© : 'audience_architect_final_report.csv'")
print("‚ïê"*70)